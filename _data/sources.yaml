- id: doi:10.1371/journal.pcbi.1007128
  type: paper
  description: Lorem ipsum _dolor_ **sit amet**, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
  date: 2020-12-4
  image: https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=info:doi/10.1371/journal.pcbi.1007128.g001&rev=2
  buttons:
    - type: manubot
      link: https://greenelab.github.io/meta-review/
    - type: source
      text: Manuscript Source
      link: https://github.com/greenelab/meta-review
    - type: website
      link: http://manubot.org/
  tags:
    - open science
    - collaboration
  repo: greenelab/meta-review

- id: doi:10.1016/j.csbj.2020.05.017
  image: https://ars.els-cdn.com/content/image/1-s2.0-S2001037020302804-gr1.jpg

- id: doi:10.7554/eLife.32822
  image: https://iiif.elifesciences.org/lax:32822%2Felife-32822-fig8-v3.tif/full/863,/0/default.webp

- id: doi:10.1109/LRA.2025.3542323
  image: https://journals.plos.org/ploscompbiol/article/figure/image?size=inline&id=info:doi/10.1371/journal.pcbi.1007128.g001&rev=2

- id: doi:10.48550/arXiv.2502.05485
  type: paper
  description: The paper addresses the challenge of generalization in robotics due to the lack of training data. It proposes a hierarchical vision-language-action (VLA) model that improves the use of off-domain data (e.g., videos, sketches, simulations). Instead of directly predicting actions, the model first generates a coarse 2D path for the robotâ€™s end-effector based on an image and task description. This path then guides a lower-level 3D control policy for precise execution. This approach reduces the burden on both levels of the model and improves generalization across different domains. Real-world experiments show a 20% improvement in success rates compared to OpenVLA, representing a 50% relative gain.
  date: 2025-2-14
  image: https://hamster-robot.github.io/figs/hamster_training_fig.png
  buttons:
    - type: website
      link: https://hamster-robot.github.io/
  # tags:
  #  - robotics

- url: https://arxiv.org/abs/2411.19309
  image: https://grape-vla.github.io/static/images/grape_model.png